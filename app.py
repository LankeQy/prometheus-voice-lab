# app.py
import gradio as gr
import torch
import torchaudio

from speechbrain.inference.classifiers import EncoderClassifier
from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan
import yt_dlp
import os
import uuid
import traceback

# ---- 1. æ¨¡å‹åŠ è½½ ----
print("æ­£åœ¨åŠ è½½æ‰€æœ‰æ¨¡å‹ï¼Œè¿™å°†éœ€è¦å‡ åˆ†é’Ÿ...")
device = "cuda:0" if torch.cuda.is_available() else "cpu"

try:
    speaker_model = EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-xvect-voxceleb",
        savedir="pretrained_models/spkrec-xvect-voxceleb",
        run_opts={"device": device}
    )
    print("âœ… å£°çº¹æå–æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"ğŸ”´ å£°çº¹æå–æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    speaker_model = None

try:
    tts_processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts", language="zh-cn")
    tts_model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts").to(device)
    tts_vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan").to(device)
    print("âœ… TTS è¯•å¬æ¨¡å‹åŠ è½½æˆåŠŸ (å·²é…ç½®ä¸­æ–‡)ï¼")
except Exception as e:
    print(f"ğŸ”´ TTS è¯•å¬æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    tts_model = None

print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œåº”ç”¨å‡†å¤‡å°±ç»ªï¼")


# ---- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
def process_audio_and_get_name(filepath, source_info="file"):
    """
    åŠ è½½ã€é‡é‡‡æ ·å¹¶æ¸…ç†éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å›æ³¢å½¢å’ŒåŸºæœ¬åç§°ã€‚
    """
    if filepath is None: return None, None
    print(f"æ­£åœ¨å¤„ç†æ¥è‡ª '{source_info}' çš„éŸ³é¢‘: {filepath}")
    try:
        signal, fs = torchaudio.load(filepath)
        # ç¡®ä¿é‡‡æ ·ç‡ä¸º 16kHz
        if fs != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=fs, new_freq=16000)
            signal = resampler(signal)
        # è½¬æ¢ä¸ºå•å£°é“
        if signal.shape[0] > 1:
            signal = torch.mean(signal, dim=0, keepdim=True)

        source_name = os.path.splitext(os.path.basename(filepath))[0]

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if source_info in ["YouTube", "microphone_temp"]:
            try:
                os.remove(filepath)
                print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {filepath}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ '{filepath}': {e}")

        return signal, source_name
    except Exception as e:
        traceback.print_exc()
        raise gr.Error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")


def download_youtube_audio(youtube_url):
    """
    ä½¿ç”¨ yt-dlp ä» URL ä¸‹è½½éŸ³é¢‘å¹¶è¿”å›æ–‡ä»¶è·¯å¾„ã€‚
    """
    if not youtube_url: return None
    print(f"æ­£åœ¨ä» URL ä¸‹è½½: {youtube_url}")
    # åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶å
    temp_filename = os.path.join("/tmp", f"temp_audio_{uuid.uuid4().hex}")

    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'wav',
        }],
        'outtmpl': temp_filename,  # æŒ‡å®šè¾“å‡ºæ¨¡æ¿ï¼Œä¸å¸¦æ‰©å±•å
        'quiet': True,
        'nocheckcertificate': True
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([youtube_url])
        output_path = f"{temp_filename}.wav"  # yt-dlp ä¼šè‡ªåŠ¨æ·»åŠ æ‰©å±•å
        if not os.path.exists(output_path):
            # æœ‰æ—¶æ‰©å±•åå¯èƒ½æ˜¯å…¶ä»–æ ¼å¼ï¼Œåšä¸€ä¸ªåå¤‡æ£€æŸ¥
            possible_files = [f for f in os.listdir("/tmp") if f.startswith(os.path.basename(temp_filename))]
            if not possible_files: raise FileNotFoundError("yt-dlp ä¸‹è½½åæœªæ‰¾åˆ°ä»»ä½•éŸ³é¢‘æ–‡ä»¶ã€‚")
            # å°†æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶é‡å‘½åä¸ºæœŸæœ›çš„ .wav æ–‡ä»¶
            found_file = os.path.join("/tmp", possible_files[0])
            os.rename(found_file, output_path)

        print(f"URL éŸ³é¢‘å·²ä¸‹è½½åˆ°: {output_path}")
        return output_path
    except Exception as e:
        traceback.print_exc()
        raise gr.Error(f"URL ä¸‹è½½æˆ–å¤„ç†å¤±è´¥: {e}")


def generate_and_test(audio_file, mic_input, youtube_url, text_to_speak):
    """
    ä¸»é€»è¾‘å‡½æ•°ï¼šæ¥æ”¶è¾“å…¥ï¼Œç”Ÿæˆå£°çº¹å’Œè¯•å¬éŸ³é¢‘ã€‚
    """
    # æ£€æŸ¥è¾“å…¥
    if not any([audio_file, mic_input, youtube_url]):
        raise gr.Error("è¯·æä¾›ä¸€ä¸ªéŸ³é¢‘æºï¼šä¸Šä¼ æ–‡ä»¶ã€å½•éŸ³æˆ–è§†é¢‘é“¾æ¥ã€‚")
    if not text_to_speak:
        raise gr.Error("è¯·è¾“å…¥è¦è¯•å¬çš„æ–‡æœ¬ã€‚")
    if speaker_model is None or tts_model is None:
        raise gr.Error("æ ¸å¿ƒæ¨¡å‹æœªèƒ½åŠ è½½ï¼Œåº”ç”¨æ— æ³•å·¥ä½œã€‚è¯·æ£€æŸ¥å¯åŠ¨æ—¥å¿—ã€‚")

    waveform, source_name = None, "audio"

    # æ ¹æ®è¾“å…¥æºå¤„ç†éŸ³é¢‘
    if youtube_url:
        youtube_filepath = download_youtube_audio(youtube_url)
        waveform, source_name = process_audio_and_get_name(youtube_filepath, "YouTube")
    elif audio_file is not None:
        # å…³é”®ä¿®å¤ï¼šGradio 4.x ç›´æ¥è¿”å›æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯æ–‡ä»¶å¯¹è±¡
        waveform, source_name = process_audio_and_get_name(audio_file, "file")
    elif mic_input is not None:
        waveform, source_name = process_audio_and_get_name(mic_input, "microphone_temp")
        source_name = "mic_recording"

    if waveform is None:
        raise gr.Error("æ— æ³•ä»æä¾›çš„æºåŠ è½½éŸ³é¢‘ã€‚")

    print("æ­£åœ¨ç”Ÿæˆå£°çº¹...")
    with torch.no_grad():
        # SpeechBrain çš„ encode_batch æœŸæœ› (batch, time)ï¼Œæˆ‘ä»¬çš„ waveform æ˜¯ (1, time)ï¼Œæ­£å¥½ç¬¦åˆ
        embedding = speaker_model.encode_batch(waveform.to(device))
        embedding = torch.nn.functional.normalize(embedding, dim=2)
        # è¾“å‡ºå½¢çŠ¶æ˜¯ (1, 1, 512)ï¼Œæå–å‡º (512,) çš„å‘é‡
        final_embedding = embedding.squeeze()

    pt_filename = f"{source_name}_embedding.pt"
    torch.save(final_embedding, pt_filename)
    print(f"å£°çº¹æ–‡ä»¶å·²ä¿å­˜: {pt_filename}")

    print("æ­£åœ¨è¿›è¡ŒTTSè¯•å¬...")
    inputs = tts_processor(text=text_to_speak, return_tensors="pt").to(device)
    # SpeechT5 éœ€è¦ (1, 512) å½¢çŠ¶çš„ embedding
    speaker_embeddings_for_tts = final_embedding.unsqueeze(0).to(device)

    speech = tts_model.generate_speech(inputs["input_ids"], speaker_embeddings_for_tts, vocoder=tts_vocoder)

    test_audio_filename = f"test_{source_name}.wav"
    # torchaudio.save éœ€è¦ (channels, time) æ ¼å¼
    torchaudio.save(test_audio_filename, speech.cpu().unsqueeze(0), 16000)
    print(f"è¯•å¬éŸ³é¢‘å·²ç”Ÿæˆ: {test_audio_filename}")

    return pt_filename, test_audio_filename


# ---- 3. Gradio ç•Œé¢å®šä¹‰ ----
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸš€ æ™®ç½—ç±³ä¿®æ–¯æ——èˆ°å£°éŸ³å®éªŒå®¤")
    gr.Markdown("åœ¨è¿™é‡Œç”Ÿäº§ã€å¹¶å³æ—¶æµ‹è¯•ç”¨äºæ‚¨ AI å¤§chaè„‘çš„ä»»ä½•å£°éŸ³ã€‚")
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### 1. æä¾›å£°éŸ³æº (ä¸‰é€‰ä¸€)")
            with gr.Tabs():
                with gr.TabItem("ğŸ“ ä¸Šä¼ æ–‡ä»¶"):
                    # Gradio 4.x, type='filepath' æ˜¯é»˜è®¤å€¼ï¼Œè¿”å›å­—ç¬¦ä¸²è·¯å¾„
                    audio_file_input = gr.File(label="æ”¯æŒ WAV, MP3, M4A ç­‰æ ¼å¼")
                with gr.TabItem("ğŸ”— è§†é¢‘å¹³å°é“¾æ¥"):
                    youtube_input = gr.Textbox(label="ç²˜è´´ YouTube, Bilibili, æŠ–éŸ³ç­‰ URL",
                                               placeholder="https://www.bilibili.com/video/BV...")
                with gr.TabItem("ğŸ¤ éº¦å…‹é£å½•åˆ¶"):
                    mic_input = gr.Audio(sources=["microphone"], type="filepath", label="ç‚¹å‡»å½•åˆ¶ä½ çš„å£°éŸ³")

            gr.Markdown("### 2. è¾“å…¥è¯•å¬æ–‡æœ¬")
            text_input = gr.Textbox(label="è¾“å…¥è¦è¯•å¬çš„ä¸­æ–‡", value="ä½ å¥½ï¼Œæˆ‘æ˜¯æ™®ç½—ç±³ä¿®æ–¯ã€‚è¿™æ˜¯æˆ‘çš„æ–°å£°éŸ³ã€‚")

            generate_btn = gr.Button("ç”Ÿæˆå¹¶è¯•å¬", variant="primary")

        with gr.Column(scale=1):
            gr.Markdown("### 3. è·å–ç»“æœ")
            pt_output = gr.File(label="ä¸‹è½½å£°çº¹ (.pt æ–‡ä»¶)")
            audio_output = gr.Audio(label="è¯•å¬å…‹éš†æ•ˆæœ", type="filepath")

    generate_btn.click(
        fn=generate_and_test,
        inputs=[audio_file_input, mic_input, youtube_input, text_input],
        outputs=[pt_output, audio_output],
        api_name="generate"
    )

# ---- 4. å¯åŠ¨åº”ç”¨ ----
if __name__ == "__main__":
    demo.launch()